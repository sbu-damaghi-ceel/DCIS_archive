{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####The spatial function values generated using R from cell assignment under dir /mnt/data10/shared/yujie/DCIS/ANALYSIS/IHC_communityAssignment\n",
    "#####And hull JSons under /mnt/data10/shared/yujie/DCIS/ANALYSIS/concaveHulls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def integrate_range(r_values, val, theo, lower_bound, upper_bound):\n",
    "    \"\"\"Integrate the (val - theo) for a specific range.\"\"\"\n",
    "    mask = (np.array(r_values) >= lower_bound) & (np.array(r_values) < upper_bound)\n",
    "    r_filtered = np.array(r_values)[mask]\n",
    "    val_minus_theo = np.array(val)[mask] - np.array(theo)[mask]\n",
    "    integration = np.trapz(val_minus_theo, r_filtered)\n",
    "    return integration\n",
    "\n",
    "def initialize_columns():\n",
    "    \"\"\"Initialize the columns for the DataFrame.\"\"\"\n",
    "    columns = ['patient_cluster']  # Add 'patient_cluster' as the first column\n",
    "    range_list = [(0, 10),(10,20), (20, 30), (30, 40), (40, 50), \n",
    "                                             (50, 60), (60, 70), (70, 80), (80, 90),(90, 100)]\n",
    "    #GFL for all points\n",
    "    for function in ['G', 'F', 'L']:\n",
    "        for range_bounds in range_list:\n",
    "            columns.append(f\"{function}_{range_bounds[0]}<=r<{range_bounds[1]}\")\n",
    "    ###GFL for single marker positive points\n",
    "    stains = ['CA9','Glut1','LAMP2b']\n",
    "    for stain in stains:\n",
    "        for function in ['subG', 'subF','subL']:\n",
    "            for range_bounds in range_list:\n",
    "                columns.append(f\"{stain}_{function}_{range_bounds[0]}<=r<{range_bounds[1]}\")\n",
    "    ###GL cross for 2-marker pair\n",
    "    mark_pairs = [('CA9', 'Glut1'), ('CA9', 'LAMP2b'), ('Glut1', 'LAMP2b')]\n",
    "    for i, j in mark_pairs:\n",
    "        pair_name = f\"{i}&{j}\"\n",
    "        for function in ['G_cross', 'L_cross']:\n",
    "            for range_bounds in range_list:\n",
    "                columns.append(f\"{pair_name}_{function}_{range_bounds[0]}<=r<{range_bounds[1]}\")\n",
    "    \n",
    "    return columns\n",
    "\n",
    "def process_json_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        all_data = json.load(file)\n",
    "\n",
    "    # Initialize columns\n",
    "    columns = initialize_columns()\n",
    "    range_list = [(0, 10),(10,20), (20, 30), (30, 40), (40, 50), \n",
    "                                             (50, 60), (60, 70), (70, 80), (80, 90),(90, 100)]\n",
    "    rows = []\n",
    "\n",
    "    # Process each key in the JSON data\n",
    "    for key, data in all_data.items():\n",
    "        row = {'patient_cluster': key}  # Initialize row with patient_cluster key\n",
    "\n",
    "        # Initialize all other columns with NA\n",
    "        for col in columns[1:]:\n",
    "            row[col] = None\n",
    "\n",
    "        # Integrate for G, F, L\n",
    "        for function in ['G', 'F', 'L']:\n",
    "            for range_bounds in range_list:\n",
    "                column_name = f\"{function}_{range_bounds[0]}<=r<{range_bounds[1]}\"\n",
    "                row[column_name] = integrate_range(\n",
    "                    data[function]['r'], data[function]['val'], data[function]['theo'], *range_bounds)\n",
    "        if isinstance(data['sub_GFL'], dict):\n",
    "            for stain, stain_data in data['sub_GFL'].items():\n",
    "                for function in ['subG', 'subF','subL']:\n",
    "                    for range_bounds in range_list:\n",
    "                        column_name = f\"{stain}_{function}_{range_bounds[0]}<=r<{range_bounds[1]}\"\n",
    "                        row[column_name] = integrate_range(\n",
    "                            stain_data[function]['r'], stain_data[function]['val'], stain_data[function]['theo'], *range_bounds)\n",
    "\n",
    "        # Integrate for cross functions if it's a dictionary\n",
    "        if isinstance(data['cross_functions'], dict):\n",
    "            for pair_name, pair_data in data['cross_functions'].items():\n",
    "                for function in ['G_cross', 'L_cross']:\n",
    "                    if function in pair_data:\n",
    "                        for range_bounds in range_list:\n",
    "                            column_name = f\"{pair_name}_{function}_{range_bounds[0]}<=r<{range_bounds[1]}\"\n",
    "                            row[column_name] = integrate_range(\n",
    "                                pair_data[function]['r'], pair_data[function]['val'], pair_data[function]['theo'], *range_bounds)\n",
    "\n",
    "        # Add the row to the list\n",
    "        rows.append(row)\n",
    "\n",
    "    # Convert list of rows to DataFrame\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "    return df\n",
    "\n",
    "\n",
    "##remove columns with too many NAs or 0s\n",
    "def cleanData(df):\n",
    "    percent_na = (df.isna()).sum() / len(df)\n",
    "    columns_to_drop_na = percent_na[percent_na > 0.3].index\n",
    "    percent_zeros = (df == 0).sum() / len(df)\n",
    "    columns_to_drop_zero = percent_zeros[percent_zeros > 0.5].index\n",
    "    columns_to_drop = set(columns_to_drop_na).union(set(columns_to_drop_zero))\n",
    "    cleaned_df = df.drop(columns=list(columns_to_drop))\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####exc44 CL 100 5\n",
    "file_path = '/mnt/data10/shared/yujie/DCIS/ANALYSIS/R_analysis/exc44_CL_100_5/exc44_CL_123_123_all_spatial_functions.json'\n",
    "df = process_json_file(file_path)\n",
    "cleaned_df = cleanData(df)\n",
    "cleaned_df.to_csv('/mnt/data10/shared/yujie/DCIS/ANALYSIS/R_analysis/exc44_CL_100_5/spat_integration.csv', index=False)\n",
    "print(cleaned_df.shape)\n",
    "print(cleaned_df.head())\n",
    "\n",
    "#####biopsy CL 100 5\n",
    "file_path = '/mnt/data10/shared/yujie/DCIS/ANALYSIS/R_analysis/biopsy_CL_100_5/biopsy_CL_123_123_all_spatial_functions.json'\n",
    "df = process_json_file(file_path)\n",
    "cleaned_df=cleanData(df)\n",
    "cleaned_df.to_csv('/mnt/data10/shared/yujie/DCIS/ANALYSIS/R_analysis/biopsy_CL_100_5/spat_integration.csv', index=False)\n",
    "print(cleaned_df.shape)\n",
    "print(cleaned_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####C 100 5\n",
    "#####exc44\n",
    "file_path = '/mnt/data10/shared/yujie/DCIS/ANALYSIS/R_analysis/exc44_C_100_5/all_spatial_functions.json'\n",
    "df = process_json_file(file_path)\n",
    "cleaned_df=cleanData(df)\n",
    "cleaned_df.to_csv('/mnt/data10/shared/yujie/DCIS/ANALYSIS/R_analysis/exc44_C_100_5/spat_integration.csv', index=False)\n",
    "print(cleaned_df.shape)\n",
    "print(cleaned_df.head())\n",
    "#####biopsy\n",
    "file_path = '/mnt/data10/shared/yujie/DCIS/ANALYSIS/R_analysis/biopsy_C_100_5/all_spatial_functions.json'\n",
    "df = process_json_file(file_path)\n",
    "cleaned_df=cleanData(df)\n",
    "cleaned_df.to_csv('/mnt/data10/shared/yujie/DCIS/ANALYSIS/R_analysis/biopsy_C_100_5/spat_integration.csv', index=False)\n",
    "print(cleaned_df.shape)\n",
    "print(cleaned_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####L 100 5\n",
    "#####exc44\n",
    "file_path = '/mnt/data10/shared/yujie/DCIS/ANALYSIS/R_analysis/exc44_L_100_5/all_spatial_functions.json'\n",
    "df = process_json_file(file_path)\n",
    "cleaned_df=cleanData(df)\n",
    "cleaned_df.to_csv('/mnt/data10/shared/yujie/DCIS/ANALYSIS/R_analysis/exc44_L_100_5/spat_integration.csv', index=False)\n",
    "print(cleaned_df.shape)\n",
    "print(cleaned_df.head())\n",
    "#####biopsy\n",
    "file_path = '/mnt/data10/shared/yujie/DCIS/ANALYSIS/R_analysis/biopsy_L_100_5/all_spatial_functions.json'\n",
    "df = process_json_file(file_path)\n",
    "cleaned_df=cleanData(df)\n",
    "cleaned_df.to_csv('/mnt/data10/shared/yujie/DCIS/ANALYSIS/R_analysis/biopsy_L_100_5/spat_integration.csv', index=False)\n",
    "print(cleaned_df.shape)\n",
    "print(cleaned_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsmil",
   "language": "python",
   "name": "dsmil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
